{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!rm -rf probabilistic-lexicon-classification"
      ],
      "metadata": {
        "id": "EMZHBGIEsfpn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUGo6J8JY9Xt",
        "outputId": "900f975c-834a-4c3f-80c7-4966bf800826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'probabilistic-lexicon-classification'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects:   6% (1/15)\u001b[K\rremote: Counting objects:  13% (2/15)\u001b[K\rremote: Counting objects:  20% (3/15)\u001b[K\rremote: Counting objects:  26% (4/15)\u001b[K\rremote: Counting objects:  33% (5/15)\u001b[K\rremote: Counting objects:  40% (6/15)\u001b[K\rremote: Counting objects:  46% (7/15)\u001b[K\rremote: Counting objects:  53% (8/15)\u001b[K\rremote: Counting objects:  60% (9/15)\u001b[K\rremote: Counting objects:  66% (10/15)\u001b[K\rremote: Counting objects:  73% (11/15)\u001b[K\rremote: Counting objects:  80% (12/15)\u001b[K\rremote: Counting objects:  86% (13/15)\u001b[K\rremote: Counting objects:  93% (14/15)\u001b[K\rremote: Counting objects: 100% (15/15)\u001b[K\rremote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 36 (delta 5), reused 0 (delta 0), pack-reused 21\u001b[K\n",
            "Unpacking objects: 100% (36/36), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/perathambkk/probabilistic-lexicon-classification.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/probabilistic-lexicon-classification"
      ],
      "metadata": {
        "id": "YZ69a8TRy_7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python bayeslex.py --epochs 250 cornell liu-pos.utf8 liu-neg.utf8 --optimizer admm --prefilter\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiVfae6aZDBJ",
        "outputId": "1b5feb86-6c4d-46f1-e1bc-0e16d2688aeb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(admm_rho=1.0, epochs=250, extra=None, grad_based=False, iters_per_epoch=5, max_k=0.9, neglex='liu-neg.utf8', optimizer='admm', poslex='liu-pos.utf8', prefilter=True, prefix='cornell', verbosity=0, vocab_size=50000)\n",
            "====================================\n",
            "docs: 2000\t vocabulary: 38097\t tokens per doc: 636.835\n",
            "lexicon sizes: 1448\t3080\n",
            "OOO baseline:\t0.696\t0.765\n",
            "OOO presence:\t0.711\t0.770\n",
            "OOO pmi:\t0.712\t0.761\n",
            "c_hat= 545.7194884208576\n",
            "prefiltering from 1448,3080 to 874,1868\n",
            "ADMM optimization\n",
            "done!\tit=50\tdual=7.03e-10<min(2.32e-08,3.39e-08)\tprimal=7.50e-12<7.92e-10\n",
            "OOO LexiMom:\t0.737\t0.810\n",
            "OOO LexiMom-Bayes:\t0.750\t0.824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import sys\n",
        "import argparse\n",
        "\n",
        "import admm\n",
        "from bayeslex_data import getLex, loadData, loadExtraData\n",
        "from bayeslex_baselines import pmiPredictor, getLexClassifier\n",
        "from bayeslex_eval import threeClassAcc, resultString\n",
        "from bayeslex_opt import BayesLexOptimizer\n",
        "from bayeslex_stats import estimateDCMFromMOM,computeR,computeRNonBayes,scale,makePredictionsKPerWord"
      ],
      "metadata": {
        "id": "ERCXE4Noy8pd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('prefix')\n",
        "parser.add_argument('poslex')\n",
        "parser.add_argument('neglex')\n",
        "parser.add_argument('--vocab_size',default=50000,type=int)\n",
        "parser.add_argument('--epochs',default=200,type=int)\n",
        "parser.add_argument('--iters_per_epoch',default=5,type=int)\n",
        "parser.add_argument('--optimizer',default='admm')\n",
        "parser.add_argument('--admm_rho',default=1.0,type=float)\n",
        "parser.add_argument('--max_k',default=0.9,type=float)\n",
        "parser.add_argument('--verbosity',default=0,type=int)\n",
        "parser.add_argument('--extra',default=None,type=str)\n",
        "\n",
        "prefilter_group = parser.add_mutually_exclusive_group(required=False)\n",
        "prefilter_group.add_argument('--prefilter',dest='prefilter',action='store_true',\n",
        "                             help=\"\"\"Prefilter the vocabulary to only include items\n",
        "                             whose observed cross-lexicon counts are lower than expected.\n",
        "                             Does not seem to make things better.\"\"\")\n",
        "prefilter_group.add_argument('--no-prefilter',dest='prefilter',action='store_false')\n",
        "parser.set_defaults(prefilter=True)\n",
        "\n",
        "grad_based_group = parser.add_mutually_exclusive_group(required=False)\n",
        "grad_based_group.add_argument('--grad',dest='grad_based',action='store_true',\n",
        "                              help=\"\"\"Use gradient-based optimization inside ADMM inner loop\"\"\")\n",
        "grad_based_group.add_argument('--quadratic',dest='grad_based',action='store_false',\n",
        "                              help=\"\"\"Use closed-form quadratic optimization inside ADMM inner loop\"\"\")\n",
        "parser.set_defaults(grad_based=False)"
      ],
      "metadata": {
        "id": "mmgFBlVuzDFP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = parser.parse_args([\"cornell\",\"liu-pos.utf8\", \"liu-neg.utf8\"])"
      ],
      "metadata": {
        "id": "OfSH0nFqzDHg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUcwXlUIzDJ_",
        "outputId": "25e0dd36-4102-47ce-8673-62e23c456c67"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Namespace(admm_rho=1.0, epochs=200, extra=None, grad_based=False, iters_per_epoch=5, max_k=0.9, neglex='liu-neg.utf8', optimizer='admm', poslex='liu-pos.utf8', prefilter=True, prefix='cornell', verbosity=0, vocab_size=50000)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y,x,vocab = loadData(args.prefix,args.vocab_size)\n",
        "    \n",
        "print(args)\n",
        "print(\"====================================\")\n",
        "print(\"docs: %d\\t vocabulary: %d\\t tokens per doc: %.3f\"%(x.shape[0],x.shape[1],x.sum(axis=1).mean()))\n",
        "pos_lex = getLex(args.poslex,vocab)\n",
        "neg_lex = getLex(args.neglex,vocab)\n",
        "print(\"lexicon sizes: %d\\t%d\"%(len(pos_lex),len(neg_lex)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2HlckKkzDMV",
        "outputId": "a05f9de1-97a9-470e-d972-bd5866c84e9a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(admm_rho=1.0, epochs=200, extra=None, grad_based=False, iters_per_epoch=5, max_k=0.9, neglex='liu-neg.utf8', optimizer='admm', poslex='liu-pos.utf8', prefilter=True, prefix='cornell', verbosity=0, vocab_size=50000)\n",
            "====================================\n",
            "docs: 2000\t vocabulary: 38097\t tokens per doc: 636.835\n",
            "lexicon sizes: 1448\t3080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = getLexClassifier(pos_lex,neg_lex,vocab)\n",
        "    \n",
        "pred_baseline = np.array(clf.dot(x.T).todense())[0] \n",
        "print(resultString(scale(pred_baseline,x),y,\"baseline\"))\n",
        "\n",
        "pred_presence = np.array(clf.dot((x>0).T).todense())[0] \n",
        "print(resultString(scale(pred_presence,x),y,\"presence\"))\n",
        "\n",
        "pred_pmi = pmiPredictor(x,pos_lex,neg_lex)\n",
        "print(resultString(scale(pred_pmi,x),y,\"pmi\"))\n",
        "\n",
        "e_mu, c_hat = estimateDCMFromMOM(x)\n",
        "print('c_hat=',c_hat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FCobQVW0bz_",
        "outputId": "8145531e-8b80-4b71-859e-6a2120090fa4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOO baseline:\t0.696\t0.765\n",
            "OOO presence:\t0.711\t0.770\n",
            "OOO pmi:\t0.712\t0.761\n",
            "c_hat= 545.7194884208576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if args.extra is not None:\n",
        "    x_train = sp.sparse.vstack([x,loadExtraData(args.extra,vocab)])\n",
        "else:\n",
        "    x_train = x"
      ],
      "metadata": {
        "id": "t5mT31cr0ghE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = BayesLexOptimizer(x_train,pos_lex,neg_lex,\n",
        "                                prefilter=args.prefilter,\n",
        "                                max_k=args.max_k,\n",
        "                                verbosity=args.verbosity)\n",
        "if args.optimizer == 'admm':\n",
        "    print('ADMM optimization')\n",
        "    opt.estimateADMM(max_iter=args.iters_per_epoch,\n",
        "                      n_epochs=args.epochs,\n",
        "                      rho=args.admm_rho,\n",
        "                      grad_based=args.grad_based\n",
        "    )\n",
        "elif args.optimizer == 'slsqp':\n",
        "    print('SLSQP optimization (warning, slow!)')\n",
        "    opt.estimateSLSQP(max_iter=args.iters_per_epoch,\n",
        "                      n_epochs=args.epochs)\n",
        "else:\n",
        "    raise Exception('Valid optimizers are admm and slsqp only')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56mdfkXW0hUk",
        "outputId": "06c11249-6d99-49a0-b926-5916ad13c099"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prefiltering from 1448,3080 to 874,1868\n",
            "ADMM optimization\n",
            "done!\tit=50\tdual=7.03e-10<min(2.32e-08,3.39e-08)\tprimal=7.50e-12<7.92e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_khat = makePredictionsKPerWord(x,opt.pos_lex,opt.neg_lex,opt.k_pos,opt.k_neg,c_hat,bayesian=False)\n",
        "print(resultString(pred_khat,y,\"LexiMom\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lt7ftYym0hXM",
        "outputId": "57f97321-bdce-434f-e4d6-4f4009c31816"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOO LexiMom:\t0.737\t0.810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_khat_bayes = makePredictionsKPerWord(x,opt.pos_lex,opt.neg_lex,opt.k_pos,opt.k_neg,c_hat,bayesian=True)\n",
        "print(resultString(pred_khat_bayes,y,\"LexiMom-Bayes\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVVBYEmK0haI",
        "outputId": "b1ab81a2-c5c3-449c-a620-b6e85de8c7a3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOO LexiMom-Bayes:\t0.750\t0.824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KvoQ-pDX0hcP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}